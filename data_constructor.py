#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
data_constructor.py - ä½¿ç”¨GPT-4.1æ„é€ ç¬¦åˆç‰¹æ®Štokenæ ¼å¼çš„è®­ç»ƒæ•°æ® (åŸºäºparquetæ•°æ®)

æ–°çš„æ„é€ æµç¨‹ï¼š
1. ä»parquetæ–‡ä»¶è¯»å–ç¼–ç¨‹é—®é¢˜
2. ä½¿ç”¨GPT-4.1ç”Ÿæˆæœ‰å°é”™è¯¯çš„ä»£ç 
3. æ ¹æ®éœ€æ±‚(Agent/Edit)åŒ…è£…æˆinstruction
4. ä½¿ç”¨GPT-4.1ç”ŸæˆåŒ…å«ç‰¹æ®Štokençš„output
"""

import os
import json
import time
import random
import re
import threading
import pandas as pd
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import List, Dict, Tuple, Optional
import openai
from openai import OpenAI

# è®¾ç½®OpenAI API (å»¶è¿Ÿåˆå§‹åŒ–)
client = None

def get_openai_client():
    """è·å–OpenAIå®¢æˆ·ç«¯ï¼Œå»¶è¿Ÿåˆå§‹åŒ–"""
    global client
    if client is None:
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise ValueError("è¯·è®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡")
        client = OpenAI(
            api_key=api_key,
            base_url="https://api.chatanywhere.tech/v1"
        )
    return client

# æ•°æ®æ–‡ä»¶è·¯å¾„
PARQUET_FILE = "data/test-00000-of-00001.parquet"

def extract_think_content(output: str) -> Tuple[str, str]:
    """æå– think éƒ¨åˆ†å’Œé think éƒ¨åˆ†çš„å†…å®¹"""
    think_pattern = r'<think>(.*?)</think>'
    think_matches = re.findall(think_pattern, output, re.DOTALL)
    think_content = '\n'.join(think_matches) if think_matches else ''
    non_think_content = re.sub(think_pattern, '', output, flags=re.DOTALL).strip()
    return think_content, non_think_content

def check_special_markers(non_think_content: str) -> Tuple[bool, str]:
    """æ£€æŸ¥æ˜¯å¦åŒ…å«ç‰¹æ®Šè¯ç¬¦"""
    if '<|EDIT|>' in non_think_content:
        return True, 'EDIT'
    elif '<|AGENT|>' in non_think_content:
        return True, 'AGENT'
    else:
        return False, 'NONE'

def check_function_call(content: str, expected_function: str) -> bool:
    """æ£€æŸ¥æ˜¯å¦æ­£ç¡®è°ƒç”¨äº†æŒ‡å®šçš„å‡½æ•°"""
    function_call_pattern = r'{\s*"name"\s*:\s*"([^"]+)"'
    matches = re.findall(function_call_pattern, content)
    return expected_function in matches

def validate_output(output: str) -> Tuple[bool, List[str]]:
    """éªŒè¯è¾“å‡ºæ˜¯å¦ç¬¦åˆæ ¼å¼è¦æ±‚"""
    issues = []
    
    # æ£€æŸ¥thinkéƒ¨åˆ†
    think_content, non_think_content = extract_think_content(output)
    if not think_content.strip():
        issues.append('ç¼ºå°‘ <think> éƒ¨åˆ†')
    
    # æ£€æŸ¥ç‰¹æ®Šè¯ç¬¦
    has_marker, marker_type = check_special_markers(non_think_content)
    if not has_marker:
        issues.append('ç¼ºå°‘ç‰¹æ®Šè¯ç¬¦ <|EDIT|> æˆ– <|AGENT|>')
        return False, issues
    
    # æ£€æŸ¥å‡½æ•°è°ƒç”¨
    if marker_type == 'AGENT':
        if not check_function_call(non_think_content, 'python'):
            issues.append('<|AGENT|> åæœªæ­£ç¡®è°ƒç”¨ python å‡½æ•°')
    elif marker_type == 'EDIT':
        if not check_function_call(non_think_content, 'editor'):
            issues.append('<|EDIT|> åæœªæ­£ç¡®è°ƒç”¨ editor å‡½æ•°')
    
    return len(issues) == 0, issues

def load_programming_problems(parquet_path: str) -> List[Dict]:
    """ä»parquetæ–‡ä»¶åŠ è½½ç¼–ç¨‹é—®é¢˜"""
    try:
        df = pd.read_parquet(parquet_path)
        problems = []
        
        for _, row in df.iterrows():
            # æå–é—®é¢˜å†…å®¹ - turnså¯èƒ½æ˜¯numpyæ•°ç»„
            turns = row['turns']
            if turns is not None and hasattr(turns, '__len__') and len(turns) > 0:
                problem_text = turns[0]
                
                # æ¸…ç†é—®é¢˜æ–‡æœ¬ï¼Œæå–æ ¸å¿ƒé—®é¢˜æè¿°
                problem_desc = extract_problem_description(problem_text)
                
                problems.append({
                    'question_id': row['question_id'],
                    'question_title': row['question_title'],
                    'problem_description': problem_desc,
                    'original_text': problem_text
                })
        
        print(f"âœ… æˆåŠŸåŠ è½½ {len(problems)} ä¸ªç¼–ç¨‹é—®é¢˜")
        return problems
        
    except Exception as e:
        print(f"âŒ åŠ è½½parquetæ–‡ä»¶å¤±è´¥: {e}")
        return []

def extract_problem_description(problem_text: str) -> str:
    """ä»å®Œæ•´é—®é¢˜æ–‡æœ¬ä¸­æå–æ ¸å¿ƒé—®é¢˜æè¿°"""
    # ç§»é™¤æŒ‡ä»¤éƒ¨åˆ†
    lines = problem_text.split('\n')
    description_lines = []
    in_description = False
    
    for line in lines:
        if '### Question:' in line:
            in_description = True
            continue
        elif line.startswith('###') and in_description:
            break
        elif in_description:
            description_lines.append(line)
    
    description = '\n'.join(description_lines).strip()
    
    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°é—®é¢˜æè¿°ï¼Œè¿”å›æ•´ä¸ªæ–‡æœ¬çš„å‰éƒ¨åˆ†
    if not description:
        description = problem_text[:1000] + "..." if len(problem_text) > 1000 else problem_text
    
    return description

def generate_buggy_code(problem_desc: str, max_retries: int = 3) -> Optional[str]:
    """ä½¿ç”¨GPT-4.1ç”ŸæˆåŒ…å«å°é”™è¯¯çš„ä»£ç """
    prompt = f"""è¯·æ ¹æ®ä»¥ä¸‹ç¼–ç¨‹é—®é¢˜ï¼Œç”Ÿæˆä¸€ä¸ªåŒ…å«å°é”™è¯¯çš„Pythonä»£ç å®ç°ã€‚

é—®é¢˜æè¿°ï¼š
{problem_desc}

è¦æ±‚ï¼š
1. ä»£ç åº”è¯¥çœ‹èµ·æ¥åˆç†ï¼Œä½†åŒ…å«1-2ä¸ªå°bug
2. é”™è¯¯å¯ä»¥æ˜¯ï¼šé€»è¾‘é”™è¯¯ã€è¾¹ç•Œæ¡ä»¶é”™è¯¯ã€è¯­æ³•å°é”™è¯¯ã€ç®—æ³•å®ç°é”™è¯¯ç­‰
3. ä¸è¦ç”Ÿæˆå®Œå…¨é”™è¯¯æˆ–æ— æ³•ç†è§£çš„ä»£ç 
4. åªè¿”å›Pythonä»£ç ï¼Œä¸è¦é¢å¤–è§£é‡Š

ä»£ç æ ¼å¼ï¼š
```python
# åœ¨è¿™é‡Œå†™ä»£ç 
```
"""

    for attempt in range(max_retries):
        try:
            client = get_openai_client()
            response = client.chat.completions.create(
                model="gpt-4.1",
                messages=[
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=1000,
                timeout=30
            )
            
            code_response = response.choices[0].message.content
            
            # æå–ä»£ç 
            if code_response:
                code_match = re.search(r'```python\n(.*?)\n```', code_response, re.DOTALL)
                if code_match:
                    return code_match.group(1).strip()
                else:
                    # å¦‚æœæ²¡æœ‰ä»£ç å—ï¼Œå°è¯•æå–æ•´ä¸ªå“åº”
                    return code_response.strip()
            else:
                return None
                
        except Exception as e:
            if attempt == max_retries - 1:
                print(f"âŒ ç”Ÿæˆé”™è¯¯ä»£ç å¤±è´¥: {e}")
                return None
            time.sleep(1)
    
    return None

def create_instruction(problem_desc: str, buggy_code: str, instruction_type: str) -> str:
    """æ ¹æ®éœ€æ±‚ç±»å‹åˆ›å»ºinstruction"""
    if instruction_type == "agent":
        # Agentæ¨¡å¼ - ç”¨æˆ·æ²¡æœ‰æ˜ç¡®é”™è¯¯ä¿¡æ¯ï¼Œéœ€è¦è°ƒè¯•åˆ†æ
        templates = [
            f"è¿™ä¸ªPythonä»£ç è¿è¡Œç»“æœä¸å¯¹ï¼Œå¸®æˆ‘çœ‹çœ‹å“ªé‡Œæœ‰é—®é¢˜ï¼š\n\n{buggy_code}",
            f"æˆ‘çš„ä»£ç å¥½åƒæœ‰bugï¼Œä½†æ‰¾ä¸å‡ºæ¥ï¼š\n\n{buggy_code}",
            f"è¿™ä¸ªç®—æ³•è¾“å‡ºå¼‚å¸¸ï¼Œèƒ½å¸®æˆ‘è°ƒè¯•å—ï¼Ÿ\n\n{buggy_code}",
            f"æˆ‘å†™çš„ä»£ç é€»è¾‘ä¸å¯¹ï¼Œè¯·å¸®æˆ‘åˆ†æï¼š\n\n{buggy_code}",
            f"è¿™ä¸ªç¨‹åºæœ‰é—®é¢˜ä½†æˆ‘ä¸ç¡®å®šå“ªé‡Œé”™äº†ï¼š\n\n{buggy_code}",
            f"æˆ‘çš„ä»£ç æ€»æ˜¯æŠ¥é”™ï¼Œèƒ½å¸®æˆ‘çœ‹çœ‹å—ï¼Ÿ\n\n{buggy_code}",
            f"è¿™ä¸ªå‡½æ•°è¿”å›å€¼ä¸æ­£ç¡®ï¼Œè¯·å¸®æˆ‘è°ƒè¯•ï¼š\n\n{buggy_code}",
        ]
    else:  # editæ¨¡å¼
        # Editæ¨¡å¼ - ç”¨æˆ·æä¾›æ˜ç¡®é”™è¯¯ä¿¡æ¯ï¼Œéœ€è¦ç›´æ¥ä¿®å¤
        error_types = [
            "IndexError: list index out of range",
            "TypeError: unsupported operand type(s)",
            "NameError: name 'variable' is not defined",
            "ValueError: invalid literal for int()",
            "AttributeError: object has no attribute",
            "KeyError: key not found in dictionary",
            "ZeroDivisionError: division by zero",
            "RecursionError: maximum recursion depth exceeded",
            "SyntaxError: invalid syntax",
            "IndentationError: expected an indented block"
        ]
        
        error_msg = random.choice(error_types)
        templates = [
            f"è¿™ä¸ªPythonä»£ç æŠ¥é”™ï¼š{error_msg}ï¼Œè¯·å¸®æˆ‘ä¿®å¤ï¼š\n\n{buggy_code}",
            f"æˆ‘çš„ä»£ç å‡ºç°{error_msg.split(':')[0]}é”™è¯¯ï¼Œéœ€è¦ä¿®å¤ï¼š\n\n{buggy_code}",
            f"è¿è¡Œè¿™ä¸ªä»£ç æ—¶å‡ºç°{error_msg}ï¼Œè¯·ä¿®å¤ï¼š\n\n{buggy_code}",
            f"è¿™ä¸ªä»£ç æœ‰é”™è¯¯ï¼š{error_msg}ï¼š\n\n{buggy_code}",
        ]
    
    return random.choice(templates)

def generate_output_with_special_tokens(instruction: str, instruction_type: str, max_retries: int = 3) -> Optional[str]:
    """ä½¿ç”¨GPT-4.1ç”ŸæˆåŒ…å«ç‰¹æ®Štokençš„è¾“å‡º"""
    
    system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä»£ç è°ƒè¯•åŠ©æ‰‹ã€‚è¯·æ ¹æ®ç”¨æˆ·çš„é—®é¢˜ç±»å‹é€‰æ‹©åˆé€‚çš„å¤„ç†æ¨¡å¼ï¼š

**å¤„ç†æ¨¡å¼è§„åˆ™ï¼š**

1. **ä»£ç†æ¨¡å¼ (<|AGENT|>)** - å½“ç”¨æˆ·æ²¡æœ‰æä¾›å…·ä½“é”™è¯¯ä¿¡æ¯ï¼Œéœ€è¦åˆ†æè°ƒè¯•æ—¶ä½¿ç”¨
2. **ç¼–è¾‘æ¨¡å¼ (<|EDIT|>)** - å½“ç”¨æˆ·æä¾›äº†æ˜ç¡®é”™è¯¯ä¿¡æ¯ï¼Œå¯ä»¥ç›´æ¥ä¿®å¤æ—¶ä½¿ç”¨

**è¾“å‡ºæ ¼å¼è¦æ±‚ï¼š**

å¯¹äºä»£ç†æ¨¡å¼ï¼š
<think> åˆ†æç”¨æˆ·é—®é¢˜ï¼Œåˆ¤æ–­éœ€è¦è°ƒè¯•åˆ†æçš„åŸå›  </think>
<|AGENT|>
æˆ‘ä¼šä½¿ç”¨ä»£ç†æ¨¡å¼è¿›è¡Œå¤„ç†{"name": "python", "arguments": {"code": "ç”¨æˆ·çš„ä»£ç "}}

å¯¹äºç¼–è¾‘æ¨¡å¼ï¼š
<think> åˆ†æå…·ä½“é”™è¯¯ä¿¡æ¯ï¼Œç¡®å®šä¿®å¤æ–¹æ¡ˆ </think>
<|EDIT|>
æˆ‘ä¼šä½¿ç”¨ç¼–è¾‘æ¨¡å¼ä¿®å¤é—®é¢˜{"name": "editor", "arguments": {"original_code": "åŸå§‹ä»£ç ", "modified_code": "ä¿®å¤åçš„ä»£ç "}}

è¯·ä¸¥æ ¼æŒ‰ç…§ä¸Šè¿°æ ¼å¼è¾“å‡ºï¼Œç¡®ä¿åŒ…å«<think>éƒ¨åˆ†å’Œç›¸åº”çš„ç‰¹æ®Šè¯ç¬¦ <|EDIT|> æˆ– <|AGENT|>ã€‚"""

    for attempt in range(max_retries):
        try:
            client = get_openai_client()
            response = client.chat.completions.create(
                model="gpt-4.1",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": instruction}
                ],
                temperature=0.7,
                max_tokens=2048,
                timeout=30
            )
            
            output = response.choices[0].message.content
            
            # éªŒè¯è¾“å‡ºæ ¼å¼
            if output:
                is_valid, issues = validate_output(output)
            else:
                is_valid, issues = False, ["APIè¿”å›ç©ºå†…å®¹"]
            
            if is_valid:
                return output
            else:
                # å¦‚æœæ ¼å¼ä¸å¯¹ï¼Œåœ¨æœ€åä¸€æ¬¡å°è¯•æ—¶ä¹Ÿè¿”å›ï¼Œä¾›åˆ†æ
                if attempt == max_retries - 1:
                    return output
                else:
                    continue  # é‡è¯•
                    
        except Exception as e:
            if attempt == max_retries - 1:
                print(f"âŒ ç”Ÿæˆè¾“å‡ºå¤±è´¥: {e}")
                return None
            time.sleep(1)  # é‡è¯•å‰ç­‰å¾…
    
    return None

def process_single_problem(problem: Dict, item_id: int) -> Optional[Dict]:
    """å¤„ç†å•ä¸ªç¼–ç¨‹é—®é¢˜ï¼Œç”Ÿæˆå®Œæ•´çš„è®­ç»ƒæ ·æœ¬"""
    try:
        # æ­¥éª¤1: ç”Ÿæˆæœ‰é”™è¯¯çš„ä»£ç 
        print(f"ğŸ”§ é¡¹ç›® {item_id}: ç”Ÿæˆé”™è¯¯ä»£ç ...")
        buggy_code = generate_buggy_code(problem['problem_description'])
        
        if not buggy_code:
            print(f"âŒ é¡¹ç›® {item_id}: ç”Ÿæˆé”™è¯¯ä»£ç å¤±è´¥")
            return None
        
        # æ­¥éª¤2: éšæœºé€‰æ‹©instructionç±»å‹
        instruction_type = random.choice(['agent', 'edit'])
        
        # æ­¥éª¤3: åˆ›å»ºinstruction
        print(f"ğŸ“ é¡¹ç›® {item_id}: åˆ›å»º{instruction_type}ç±»å‹instruction...")
        instruction = create_instruction(
            problem['problem_description'], 
            buggy_code, 
            instruction_type
        )
        
        # æ­¥éª¤4: ç”ŸæˆåŒ…å«ç‰¹æ®Štokençš„è¾“å‡º
        print(f"ğŸ¤– é¡¹ç›® {item_id}: ç”Ÿæˆç‰¹æ®Štokenè¾“å‡º...")
        output = generate_output_with_special_tokens(instruction, instruction_type)
        
        if not output:
            print(f"âŒ é¡¹ç›® {item_id}: ç”Ÿæˆè¾“å‡ºå¤±è´¥")
            return None
        
        # éªŒè¯æœ€ç»ˆè¾“å‡º
        if output:
            is_valid, issues = validate_output(output)
        else:
            is_valid, issues = False, ["ç”Ÿæˆè¾“å‡ºä¸ºç©º"]
        
        result = {
            'item_id': item_id,
            'question_id': problem['question_id'],
            'question_title': problem['question_title'],
            'instruction': instruction,
            'output': output,
            'expected_type': instruction_type,
            'buggy_code': buggy_code,
            'valid': is_valid,
            'issues': issues
        }
        
        status = "âœ… æœ‰æ•ˆ" if is_valid else f"âŒ æ— æ•ˆ: {', '.join(issues)}"
        print(f"âœ“ å®Œæˆé¡¹ç›® {item_id}: {instruction_type.upper()} - {status}")
        
        return result
        
    except Exception as e:
        print(f"âŒ é¡¹ç›® {item_id} å¤„ç†å¤±è´¥: {e}")
        return None

def construct_training_data_from_parquet(
    num_samples: int = 100, 
    num_threads: int = 32, 
    output_file: str = "outputs/training_data/training_data_from_parquet.json"
) -> List[Dict]:
    """ä»parquetæ•°æ®æ„é€ è®­ç»ƒæ•°æ®"""
    
    print(f"ğŸš€ å¼€å§‹ä»parquetæ•°æ®æ„é€  {num_samples} ä¸ªè®­ç»ƒæ ·æœ¬...")
    print(f"ğŸ”§ ä½¿ç”¨ {num_threads} ä¸ªçº¿ç¨‹")
    print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶: {output_file}")
    print("=" * 50)
    
    # åŠ è½½ç¼–ç¨‹é—®é¢˜
    problems = load_programming_problems(PARQUET_FILE)
    
    if not problems:
        print("âŒ æ— æ³•åŠ è½½ç¼–ç¨‹é—®é¢˜ï¼Œé€€å‡º")
        return []
    
    # å¦‚æœè¯·æ±‚çš„æ ·æœ¬æ•°è¶…è¿‡å¯ç”¨é—®é¢˜æ•°ï¼Œå°±å¾ªç¯ä½¿ç”¨
    if num_samples > len(problems):
        print(f"âš ï¸  è¯·æ±‚æ ·æœ¬æ•°({num_samples})è¶…è¿‡å¯ç”¨é—®é¢˜æ•°({len(problems)})ï¼Œå°†å¾ªç¯ä½¿ç”¨é—®é¢˜")
    
    selected_problems = []
    for i in range(num_samples):
        problem_idx = i % len(problems)
        selected_problems.append(problems[problem_idx])
    
    results = []
    valid_count = 0
    invalid_count = 0
    
    # ä½¿ç”¨çº¿ç¨‹æ± æ‰§è¡Œ
    with ThreadPoolExecutor(max_workers=num_threads) as executor:
        # æäº¤ä»»åŠ¡
        future_to_id = {
            executor.submit(process_single_problem, problem, i): i 
            for i, problem in enumerate(selected_problems)
        }
        
        # æ”¶é›†ç»“æœ
        for future in as_completed(future_to_id):
            result = future.result()
            if result:
                results.append(result)
                if result["valid"]:
                    valid_count += 1
                else:
                    invalid_count += 1
    
    print("\n" + "=" * 50)
    print(f"ğŸ“Š æ„é€ å®Œæˆç»Ÿè®¡:")
    print(f"   æ€»æ ·æœ¬æ•°: {len(results)}")
    print(f"   âœ… æœ‰æ•ˆæ ·æœ¬: {valid_count}")
    print(f"   âŒ æ— æ•ˆæ ·æœ¬: {invalid_count}")
    print(f"   ğŸ“ˆ æœ‰æ•ˆç‡: {valid_count/len(results)*100:.1f}%" if results else "0%")
    
    # ä¿å­˜æ‰€æœ‰æ•°æ®ï¼ˆåŒ…æ‹¬æ— æ•ˆçš„ï¼Œä¾›åˆ†æï¼‰
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ’¾ åŸå§‹æ•°æ®å·²ä¿å­˜åˆ°: {output_file}")
    
    # æå–æœ‰æ•ˆæ•°æ®å¹¶è½¬æ¢ä¸ºalpacaæ ¼å¼
    valid_data = [item for item in results if item["valid"]]
    alpaca_data = convert_to_alpaca_format(valid_data)
    
    # ç¡®ä¿ç›®å½•å­˜åœ¨
    import os
    os.makedirs(os.path.dirname(output_file), exist_ok=True)
    
    alpaca_file = output_file.replace('.json', '_alpaca.json')
    with open(alpaca_file, 'w', encoding='utf-8') as f:
        json.dump(alpaca_data, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ“¦ Alpacaæ ¼å¼æ•°æ®å·²ä¿å­˜åˆ°: {alpaca_file}")
    
    # ç”Ÿæˆåˆ†ææŠ¥å‘Šï¼ˆä¿å­˜åˆ°reportsç›®å½•ï¼‰
    base_name = os.path.basename(output_file).replace('.json', '_analysis.txt')
    report_file = f"outputs/reports/{base_name}"
    os.makedirs("outputs/reports", exist_ok=True)
    generate_analysis_report(results, report_file)
    
    return results

def convert_to_alpaca_format(data: List[Dict]) -> List[Dict]:
    """è½¬æ¢ä¸ºalpacaæ ¼å¼"""
    alpaca_data = []
    
    for item in data:
        alpaca_item = {
            "instruction": item["instruction"],
            "input": "",  # æˆ‘ä»¬çš„ä»»åŠ¡ä¸éœ€è¦é¢å¤–input
            "output": item["output"]
        }
        alpaca_data.append(alpaca_item)
    
    return alpaca_data

def generate_analysis_report(results: List[Dict], report_file: str):
    """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
    valid_results = [r for r in results if r["valid"]]
    invalid_results = [r for r in results if not r["valid"]]
    
    report = []
    report.append("=" * 60)
    report.append("åŸºäºParquetæ•°æ®çš„è®­ç»ƒæ•°æ®æ„é€ åˆ†ææŠ¥å‘Š")
    report.append("=" * 60)
    report.append(f"æ€»æ ·æœ¬æ•°: {len(results)}")
    report.append(f"æœ‰æ•ˆæ ·æœ¬: {len(valid_results)} ({len(valid_results)/len(results)*100:.1f}%)")
    report.append(f"æ— æ•ˆæ ·æœ¬: {len(invalid_results)} ({len(invalid_results)/len(results)*100:.1f}%)")
    report.append("")
    
    # æŒ‰ç±»å‹ç»Ÿè®¡
    type_stats = {}
    for result in valid_results:
        t = result["expected_type"]
        type_stats[t] = type_stats.get(t, 0) + 1
    
    report.append("æœ‰æ•ˆæ ·æœ¬ç±»å‹åˆ†å¸ƒ:")
    for t, count in type_stats.items():
        report.append(f"  {t}: {count} ({count/len(valid_results)*100:.1f}%)")
    report.append("")
    
    # æ— æ•ˆæ ·æœ¬é—®é¢˜åˆ†æ
    if invalid_results:
        issue_stats = {}
        for result in invalid_results:
            for issue in result["issues"]:
                issue_stats[issue] = issue_stats.get(issue, 0) + 1
        
        report.append("æ— æ•ˆæ ·æœ¬é—®é¢˜ç»Ÿè®¡:")
        for issue, count in sorted(issue_stats.items(), key=lambda x: x[1], reverse=True):
            report.append(f"  {issue}: {count}")
        report.append("")
    
    # é—®é¢˜æ¥æºç»Ÿè®¡
    question_stats = {}
    for result in results:
        title = result.get("question_title", "unknown")
        question_stats[title] = question_stats.get(title, 0) + 1
    
    report.append(f"é—®é¢˜æ¥æºåˆ†å¸ƒï¼ˆå‰10ä¸ªï¼‰:")
    for title, count in sorted(question_stats.items(), key=lambda x: x[1], reverse=True)[:10]:
        title_short = title[:50] + "..." if len(title) > 50 else title
        report.append(f"  {title_short}: {count}")
    report.append("")
    
    # ä¿å­˜æŠ¥å‘Š
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write('\n'.join(report))
    
    print(f"ğŸ“Š åˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='ä»parquetæ•°æ®æ„é€ ç¬¦åˆç‰¹æ®Štokenæ ¼å¼çš„è®­ç»ƒæ•°æ®')
    parser.add_argument('--samples', type=int, default=100, help='ç”Ÿæˆæ ·æœ¬æ•°é‡ (é»˜è®¤: 100)')
    parser.add_argument('--threads', type=int, default=32, help='çº¿ç¨‹æ•°é‡ (é»˜è®¤: 32)')
    parser.add_argument('--output', type=str, default='outputs/training_data/training_data_from_parquet.json', 
                       help='è¾“å‡ºæ–‡ä»¶å (é»˜è®¤: outputs/training_data/training_data_from_parquet.json)')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥API key
    if not os.getenv("OPENAI_API_KEY"):
        print("âŒ é”™è¯¯: è¯·è®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡")
        print("   export OPENAI_API_KEY='your-api-key-here'")
        return
    
    # æ£€æŸ¥parquetæ–‡ä»¶
    if not os.path.exists(PARQUET_FILE):
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°parquetæ–‡ä»¶ {PARQUET_FILE}")
        print("è¯·ç¡®ä¿æ•°æ®æ–‡ä»¶å­˜åœ¨")
        return
    
    # æ£€æŸ¥pandasä¾èµ–
    try:
        import pandas as pd
    except ImportError:
        print("âŒ é”™è¯¯: éœ€è¦å®‰è£…pandasåº“")
        print("   pip install pandas")
        return
    
    construct_training_data_from_parquet(
        num_samples=args.samples,
        num_threads=args.threads,
        output_file=args.output
    )

if __name__ == "__main__":
    main() 